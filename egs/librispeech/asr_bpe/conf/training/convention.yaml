loss: k2
gpus: ???
name: ???
output_dir: ${hydra:run.dir}
# batch
batch_size: 2
accumulate_grad_batches: 32
# data pipeline
num_workers: 4
# multi-gpu training
strategy: ddp
# optimiser
#optimiser: adam
transformer-warmup-steps: 25000
final_lr: 1e-4

lr: 1e-4
factor: 0.1
lr_patience: 2
min_lr: 1e-7

save_top_k: 10
# random seed
seed: 777
# early_stopping
early_stopping: true
patience: 20
# for debugging
max_steps: -1
max_epochs: 1000

spec_aug: true
grad_clip: 5
nowarmup: false
